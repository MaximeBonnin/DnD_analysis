{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dungeons and Dragons Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to set up all the packages we want to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to get the data.\n",
    "We are using a dataset provided as a json from https://github.com/oganm/dnddata\n",
    "\n",
    "Since the dataset is quite large (more than 7000 unique characters as of february 2022) we will first download it and save it locally. This way, we don't have to download the data again every time we run an analysis unless we want to update the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download the json from https://github.com/oganm/dnddata\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/oganm/dnddata/master/data-raw/dnd_chars_unique.json\"\n",
    "\n",
    "with requests.get(url) as content:\n",
    "    json_data = content.text\n",
    "\n",
    "data = json.loads(json_data)\n",
    "\n",
    "# Save the json file locally\n",
    "\n",
    "with open(\"json_data.json\", \"w\") as f:\n",
    "    f.writelines(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the .json file we just downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open local json file\n",
    "\n",
    "with open(\"json_data.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to go through the .json file and create a table from the data. Here we select which attributes are interesting and which ones we want to leave out.\n",
    "\n",
    "Finally, we create a dataframe from the data.\n",
    "\n",
    "At this point, we could continue the analysis using python if we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a Data Frame\n",
    "data_dict = {\n",
    "    \"Name\": [],\n",
    "    \"Race\": [],\n",
    "    \"Class\": [],\n",
    "    \"Total_lvl\": [],\n",
    "    \"Alignment\": [],\n",
    "    \"Skills\": [],\n",
    "    \"Feats\": [],\n",
    "    \"HP\": [],\n",
    "    \"AC\": [],\n",
    "    \"Str\": [], \"Dex\": [], \"Con\": [], \"Int\": [], \"Wis\": [], \"Cha\": [],\n",
    "    \"Spellcaster\": [],\n",
    "    \"Num_of_spells\": []\n",
    "}\n",
    "\n",
    "# loop through the characters in the json and pick out the attributes for analysis\n",
    "for char in data:\n",
    "    # name\n",
    "    char_name = data[char][\"name\"][\"alias\"][0]\n",
    "    data_dict[\"Name\"].append(char_name)\n",
    "\n",
    "    #race\n",
    "    char_race = data[char][\"race\"][\"processedRace\"][0]\n",
    "    data_dict[\"Race\"].append(char_race)\n",
    "\n",
    "    # class\n",
    "    class_str = \"\"\n",
    "    for cls in data[char][\"class\"]:\n",
    "        if class_str != \"\":\n",
    "            class_str = class_str + \"; \"\n",
    "        this_class = data[char][\"class\"][cls][\"class\"][0]\n",
    "        subclass = data[char][\"class\"][cls][\"subclass\"][0]\n",
    "        if subclass == \"\":\n",
    "            subclass = \"No Sub\"\n",
    "        class_lvl = data[char][\"class\"][cls][\"level\"][0]\n",
    "        this_class_str = f\"[{this_class}; {subclass}; {class_lvl}]\"\n",
    "        class_str = class_str + this_class_str\n",
    "    data_dict[\"Class\"].append(class_str)\n",
    "\n",
    "    # character level\n",
    "    total_lvl = data[char][\"level\"][0]\n",
    "    data_dict[\"Total_lvl\"].append(total_lvl)\n",
    "    \n",
    "    # alignment\n",
    "    if data[char][\"alignment\"][\"processedAlignment\"][0]:\n",
    "        alignment = data[char][\"alignment\"][\"processedAlignment\"][0]\n",
    "    else:\n",
    "        alignment = None\n",
    "    data_dict[\"Alignment\"].append(alignment)\n",
    "\n",
    "    # skills / proficiencies\n",
    "    skill_str = \"\"\n",
    "    for skill in data[char][\"skills\"]:\n",
    "        if skill_str != \"\":\n",
    "            skill_str = skill_str + \"; \"\n",
    "        skill_str = skill_str + skill\n",
    "    data_dict[\"Skills\"].append(skill_str)\n",
    "\n",
    "    # feats\n",
    "    feat_str = \"\"\n",
    "    for feat in data[char][\"feats\"]:\n",
    "        if feat_str != \"\":\n",
    "            feat_str = feat_str + \"; \"\n",
    "        feat_str = feat_str + feat\n",
    "    data_dict[\"Feats\"].append(feat_str)\n",
    "\n",
    "    # HP \n",
    "    hp = data[char][\"HP\"][0]\n",
    "    data_dict[\"HP\"].append(hp)\n",
    "\n",
    "    # AC\n",
    "    ac = data[char][\"AC\"][0]\n",
    "    data_dict[\"AC\"].append(ac)\n",
    "\n",
    "    # attributes\n",
    "    for atr in [\"Str\", \"Dex\", \"Con\", \"Int\", \"Wis\", \"Cha\"]:\n",
    "        val = data[char][\"attributes\"][atr][0]\n",
    "        data_dict[atr].append(val)\n",
    "\n",
    "    # spellcaster\n",
    "    if data[char][\"spells\"]:\n",
    "        data_dict[\"Spellcaster\"].append(True)\n",
    "    else:\n",
    "        data_dict[\"Spellcaster\"].append(False)\n",
    "\n",
    "    # number of spells\n",
    "    data_dict[\"Num_of_spells\"].append(len(data[char][\"spells\"]))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can export the data frame we created as a .csv to use for further analysis using other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dnd_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4b965e543113fef6e9316f4ed2c80afc8f7c2da2295b5640ae0e8acdae3461b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
